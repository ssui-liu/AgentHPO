{
  "num_layers": 32,
  "hidden_size": 16,
  "activation": "relu",
  "dropout": 0.5,
  "learning_rate": 1e-5,
  "weight_decay": 1e-5,
  "optimizer": "adam",
  "num_epochs": 5,
  "use_cuda": true
}